# -*- coding: utf-8 -*-
"""Faster_R-CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10D2z07CrIi6zNDzGoMxrox0jBaLS79Po
"""

#following tutorial on faster rcnn by Tien-Lung Sun
#import necessary functions
import torch
import os
import random
import numpy as np
import matplotlib.pyplot as plt
import torchvision
from torchvision import transforms, datasets, models
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
from torch import nn
import time
import cv2 #rectangle in bounding box (need to write own bounding box functiion)

#check device type (my computer does not have gpu, so cpu is used)
if (torch.cuda.is_available()):
  device = torch.device("cuda")
  print(device, torch.cuda.get_device_name(0))
else:
  device = torch.device("cpu")
  print(device)

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/VIP\ APPS\ -\ Plant\ \(SP22\)/Canny Images

img = plt.imread('dand.jpg')
print(img.shape)
plt.imshow(img)

#Set bounding box
bbox = np.array([[50,50,150,140], [50,50,150,140]])

img_clone = np.copy(img)
for i in range(len(bbox)):
  cv2.rectangle(img_clone, (bbox[i][1], bbox[i][0], bbox[i][3], bbox[i][2]), color = (0,255,0), thickness = 2)
plt.imshow(img_clone)

model = torchvision.models.vgg16(pretrained = True).to(device)
features = list(model.features)
print(len(features))

dummy_img = torch.zeros((1,3,256,256))
print(dummy_img.shape)

req_features = []
k = dummy_img.clone().to(device)
for i in features:
  k = i(k)
  req_features.append(i)
  out_channels = k.size()[1]
print(len(req_features)) 
print(out_channels)

faster_rcnn_fe_extractor = nn.Sequential(*req_features)

transform = transforms.Compose([transforms.ToTensor()])
imgTensor = transform(img).to(device)
imgTensor = imgTensor.unsqueeze(0)
out_map = faster_rcnn_fe_extractor(imgTensor)
print(out_map.size())

imgArray = out_map.data.cpu().numpy().squeeze(0)
fig = plt.figure(figsize = (12,4))
figNo = 1
for i in range(5,10):
  fig.add_subplot(1,5,figNo)
  plt.imshow(imgArray[i], cmap = 'gray')
  figNo += 1

#generate anchor boxes
fe_size = 50
ctr_x = np.arange(16, (fe_size+1) * 16, 16)
ctr_y = np.arange(16, (fe_size+1) * 16, 16)

index = 0
ctr = np.zeros((2500,2))
for x in range(len(ctr_x)):
  for y in range(len(ctr_y)):
    ctr[index,1] = ctr_x[x] - 8
    ctr[index,0] = ctr_y[y] - 8
    index += 1

img_clone = np.copy(img)
for i in range(ctr.shape[0]):
  cv2.circle(img_clone, (int(ctr[i][0]), int(ctr[i][1])), radius = 1, color = (255,0,75), thickness = 1)
plt.axis('off')
plt.imshow(img_clone)

ratios = [0.5, 1, 4]
scales = [8, 16, 32]
sub_sample = 16
anchor_boxes = np.zeros(((fe_size * fe_size * 9),4))
index = 0; 
for c in ctr:
  ctr_y, ctr_x = c;
  for i in range(len(ratios)):
    for j in range(len(scales)):
      h = sub_sample * scales[j] * np.sqrt(ratios[i])
      w = sub_sample * scales[j] * np.sqrt(1/ratios[i])
      anchor_boxes[index, 0] = ctr_y - h / 2
      anchor_boxes[index, 1] = ctr_x - w / 2
      anchor_boxes[index, 2] = ctr_y + h / 2
      anchor_boxes[index, 3] = ctr_x + w / 2
      index += 1
print(anchor_boxes.shape)

img_clone = np.copy(img)
for i in range(22500):
  x0 = int(anchor_boxes[i][1])
  y0 = int(anchor_boxes[i][0])
  x1 = int(anchor_boxes[i][3])
  y1 = int(anchor_boxes[i][2])
  cv2.rectangle(img_clone, (x0, y0), (x1, y1), color = (255,255,0))

for i in range(len(bbox)):
  cv2.rectangle(img_clone, (bbox[i][1], bbox[i][0], bbox[i][3], bbox[i][2]), color = (0,255,0), thickness = 2)
plt.axis('off')
plt.imshow(img_clone)

index_inside = np.where(
    (anchor_boxes[:,0] >= 0) &
    (anchor_boxes[:,1] >= 0) &
    (anchor_boxes[:,2] <= 256) &
    (anchor_boxes[:,3] <= 256)
)[0]
print(index_inside.shape)

valid_anchor_boxes = anchor_boxes[index_inside]
print(valid_anchor_boxes.shape)

ious = np.zeros((len(valid_anchor_boxes),2), dtype = np.int32)
for x, i in enumerate(valid_anchor_boxes):
  ya1, xa1, ya2, xa2 = i
  anchor_area = (ya2 - ya1) * (xa2 - xa1)
  for y, j in enumerate(bbox):
    yb1, xb1, yb2, xb2 = j
    box_area = (yb2 - yb1) * (xb2 - xb1)
    inter_x1 = max([xb1, xa1])
    inter_y1 = max([yb1, ya1])
    inter_x2 = max([xb2, xa2])
    inter_y2 = max([yb2, ya2])
    if ((inter_x1 < inter_x2) and (inter_y1 < inter_y2)):
      iter_area = (inter_y2 - inter_y1) * (inter_x2 - inter_x1)
      iou = iter_area / (anchor_area + box_area - iter_area)
    else:
      iou = 0
    ious[x, y] = iou
print(ious.shape)

gt_argmax_ious = ious.argmax(axis = 0)
print(gt_argmax_ious)

gt_max_ious = ious[gt_argmax_ious, np.arange(ious.shape[1])]
print(gt_max_ious)

gt_argmax_ious = np.where(ious == gt_max_ious)[0]
print(gt_argmax_ious)

argmax_ious = ious.argmax(axis = 1)
print(argmax_ious.shape)
print(argmax_ious)
max_ious = ious[np.arange(len(index_inside)), argmax_ious]
print(max_ious)

label = np.empty((len(index_inside),), dtype = np.int32)
label.fill(-1)
print(label.shape)

positive_iou_thresh = 0.7
negative_iou_thresh = 0.3
label[gt_argmax_ious] = 1
label[max_ious >= positive_iou_thresh] = 1
label[max_ious < negative_iou_thresh] = 0

n_sample = 256
pos_ratio = 0.5
n_pos= pos_ratio * n_sample

pos_index = np.where(label == 1)[0]
if (len(pos_index) > n_pos): 
  disable_index = np.random.choice(pos_index, size = (len(pos_index) - n_pos), replace = False)
  label[disable_index] = -1
n_neg = n_sample * np.sum(label == 1)
neg_index = np.where(label == 0)[0]
if (len(neg_index) > n_neg):
  disable_index = np.random.choice(neg_index, size = (len(neg_index) - n_neg), replace = False)
  label[disable_index] = -1

max_iou_bbox = bbox[argmax_ious]
print(max_iou_bbox.shape)

height = valid_anchor_boxes[:,2] - valid_anchor_boxes[:,0]
width = valid_anchor_boxes[:,3] - valid_anchor_boxes[:,1]
ctr_y = valid_anchor_boxes[:,0] + 0.5 * height
ctr_x = valid_anchor_boxes[:,1] + 0.5 * width

base_height = max_iou_bbox[:,2] - max_iou_bbox[:,0]
base_width = max_iou_bbox[:,3] - max_iou_bbox[:,1]
base_ctr_y = max_iou_bbox[:,0] + 0.5 * base_height
base_ctr_x = max_iou_bbox[:,1] + 0.5 * base_width

eps = np.finfo(height.dtype).eps
height = np.maximum(height, eps)
width = np.maximum(width, eps)
dy = (base_ctr_y - ctr_y) / height
dx = (base_ctr_x - ctr_x) / width
dh = np.log(base_height / height)
dw = np.log(base_width / width)
anchor_locs = np.vstack((dy,dx,dh,dw)).transpose()
print(anchor_locs.shape)

anchor_labels = np.empty((len(anchor_boxes),), dtype = label.dtype)
anchor_labels.fill(-1)
anchor_labels[index_inside] = label
print(anchor_labels.shape)

anchor_locations = np.empty((len(anchor_boxes),) + anchor_boxes.shape[1:], dtype = anchor_locs.dtype)
anchor_locations.fill(0)
anchor_locations[index_inside, :] = anchor_locs
print(anchor_locations.shape)