# -*- coding: utf-8 -*-
"""training.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KQYkSEdY-tGgWm3GJ4wdrwfDlbsi9pwL
"""

import numpy as np
import os
import tensorflow as tf
#import tensorflow_datasets as tfds
from tensorflow import keras, Tensor
from tensorflow.keras import layers
from tensorflow.keras.layers import Layer
from tensorflow.keras.models import Sequential
import matplotlib.pyplot as plt
tf.test.gpu_device_name()

#mounts to google drive
from google.colab import drive
drive.mount('/content/drive')

#configurations for augmenting the dataset
data_augmentation = tf.keras.Sequential([
  layers.RandomFlip("horizontal_and_vertical"),
  layers.RandomRotation(0.2),
  layers.RandomContrast(0.2),
  layers.RandomBrightness(0.2)
])


def both_filters_greyscale1_tf(image: Tensor):
  image = tf.transpose(image[0], perm=[2,0,1])[0]
  #image = tf.cast(image, tf.int32)
  #kernel to traverse x
  horizontal_filter = [[-1,0,1],
                      [-2,0,2],
                      [-1,0,1]]
  horizontal_filter = tf.constant(horizontal_filter, tf.float32)

  #kernel to traverse y
  vertical_filter =   [[-1,-2,-1],
                      [0,0,0],
                      [1,2,1]]
  vertical_filter = tf.constant(vertical_filter, tf.float32)

  height, width = image.shape
  
  new_image = tf.Variable(tf.zeros(image.shape))
  print(new_image.shape)

  filtered_x = tf.nn.conv2d(image, horizontal_filter,
                          strides=[1, 1, 1, 1], padding='SAME')
  filtered_y = tf.nn.conv2d(image, vertical_filter,
                            strides=[1, 1, 1, 1], padding='SAME')

  for i in range(1, height - 2):
    for j in range(1, width-2):
        local_pixels = image[i-1:i+2, j-1:j+2]
        
        horizontal_transformed_pixels = tf.multiply(horizontal_filter, local_pixels)
        horizontal_score = (tf.math.reduce_sum(horizontal_transformed_pixels))    #these values are not plot to 0-1 because otherwise 
                                                                    #the result becomes too dim.
    
        vertical_transformed_pixels = tf.multiply(vertical_filter, local_pixels)
        vertical_score = (tf.math.reduce_sum(vertical_transformed_pixels))
        
        edge_score = (vertical_score**2 + horizontal_score**2)**0.5
        print(horizontal_score.numpy())
        print(vertical_score.numpy())
        print(edge_score.numpy())
        new_image[i][j] = edge_score.numpy()
  return new_image

# data_dir = "/content/drive/MyDrive/sobel"
# data_dir = "/content/drive/MyDrive/Flowers/flowers"
data_dir = "/content/drive/MyDrive/Flower Images/canny_images"
img_width = 512
img_height = 512
batch_size = 32


# Gets training data from data_dir
# 80% of the total data
train_ds = tf.keras.utils.image_dataset_from_directory(
  data_dir,
  label_mode='int',
  validation_split=0.2,
  color_mode="grayscale",
  shuffle="True",
  subset="training",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

# Gets testing data from data_dir
# 20% of the total data
test_ds = tf.keras.utils.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  label_mode='int',
  subset="validation",
  color_mode="grayscale",
  shuffle=False,
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

# shows which classes are available
num_classes = len(train_ds.class_names)
print(train_ds.class_names)
print(train_ds.__len__())

# data_aug = Sequential(layers.Lambda(lambda x: both_filters_greyscale1_tf(x)))
# train_ds = train_ds.map(lambda x, y: (data_aug(x), y))


fig, ax = plt.subplots(3)
fig.set_size_inches(12,12)


for images, labels in train_ds.take(1):
  for idx in range(3):
    image = tf.transpose(images[idx], perm=[2,0,1])
    ax[idx].imshow(image[0], cmap="gray")

fig.show()

#augments the data, then concatonates augmented set with original dataset
new_ds = train_ds.map(lambda x, y: (data_augmentation(x, training=True), y))
total_ds = new_ds.concatenate(train_ds)

fig, ax = plt.subplots(3)
fig.set_size_inches(12,12)


for images, labels in new_ds.take(1):
  for idx in range(3):
    image = tf.transpose(images[idx], perm=[2,0,1])
    print(images[idx].shape)
    ax[idx].imshow(image[0], cmap="gray")

fig.show()

#11/14/2028
#Previous iteration of model
model = Sequential([
    tf.keras.layers.Rescaling(1./255),
    tf.keras.layers.Conv2D(filters=16, kernel_size=(5, 5), input_shape=(128, 128, 1), activation='relu'),
    tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same'),
    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), input_shape=(62, 62, 16), activation='relu'),
    tf.keras.layers.Conv2D(filters=4, kernel_size=(3, 3), input_shape=(60, 60, 32), activation='relu'),
    tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same'),
    tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), input_shape=(29, 29, 4), activation='relu'),
    tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same'),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(1024, activation='relu'),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(num_classes, activation='softmax')
])
model.build(input_shape=(batch_size, img_width, img_height, 1))
model.summary()

#11/28/2022: Andy Hufford
#Final iteration of model
#used to rec
model = Sequential([
    tf.keras.layers.Rescaling(1./255),
    tf.keras.layers.Conv2D(filters=16, kernel_size=(11, 11), input_shape=(128, 128, 1), activation='relu', padding='same'),
    tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same'),
    tf.keras.layers.Conv2D(filters=32, kernel_size=(7, 7), input_shape=(64, 64, 16), activation='relu', padding='same'),
    tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same'),
    tf.keras.layers.Conv2D(filters=64, kernel_size=(5, 5), input_shape=(32, 32, 32), activation='relu', padding='same'),
    tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same'),
    tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), input_shape=(16, 16, 64), activation='relu', padding='same'),
    tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), input_shape=(16, 16, 64), activation='relu', padding='same'),
    tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), input_shape=(16, 16, 64), activation='relu', padding='same'),
    tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same'),
    tf.keras.layers.Flatten(),
    # tf.keras.layers.Dense(1024, activation='relu'),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(num_classes, activation='softmax')
])
model.build(input_shape=(batch_size, img_width, img_height, 1))
model.summary()

#11/14/2022: Andy Hufford
#uses stochastic gradient descent
sgd = tf.keras.optimizers.SGD(learning_rate=.01, momentum=.9)

#compiles the model with
#loss: CrossEntropyLoss 
#optimizer: Mini-batch Gradient Descent
#measures: accuracy
model.compile(
  optimizer="SGD",
  loss=tf.losses.SparseCategoricalCrossentropy(),
  metrics=['accuracy'])

# begins training on GPU
with tf.device("/device:GPU:0"):
  history_1 = model.fit(
      # train_ds,
      total_ds,
      validation_data=test_ds,
      epochs=40
  )

#11/14/2022
#Prints results from models training and testing
#Along with graphs
print(history_1.history.keys())
#  "Accuracy"
plt.plot(history_1.history['accuracy'])
plt.plot(history_1.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()
# "Loss"
plt.plot(history_1.history['loss'])
plt.plot(history_1.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/VIP\ APPS\ -\ Plant\ \(SP22\)/Canny Images
from scipy import signal
#load image
# rawImage = plt.imread('iris.jpg')
# plt.imshow(rawImage)

#greyscale code - Joseph Huang 1/20/23
def canny(rawImage):
  row = len(rawImage)
  col = len(rawImage[1])

  redarray = np.zeros((row, col), np.dtype(np.uint8))  
  greenarray = np.zeros((row, col), np.dtype(np.uint8))
  bluearray = np.zeros((row, col), np.dtype(np.uint8))

  for i in range(row):
      for j in range(col):        
          redarray[i][j] = rawImage[i][j][0]   
          greenarray[i][j] = rawImage[i][j][1]
          bluearray[i][j] = rawImage[i][j][2] 

  grey = np.zeros((row, col), np.dtype(np.uint8)) 

  #BT.709 Equation
  grey = (0.183 * redarray) + (0.614 * greenarray) + (0.062 * bluearray)

  plt.imshow(grey, cmap='gray')

  def contrastValues(channel):
      
      # kwl 1/30/23
      # Function for determining "contrast" of image (ratio of highlights and shadows to midtones)
      
      highlights = (channel > 200).sum() # Counting number of pixels above 200 ("highlights")
      shadows = (channel < 100).sum() # Counting pixels below 100 ("shadows")
      midtones = (channel < 200).sum() - shadows # Counting values between
      
      highToMid = highlights / midtones # Ratio of highlights to midtones
      lowToMid = shadows / midtones # Ratio of shadows to midtones
      if highlights < shadows:
          extremes = highlights / shadows # Ratio of highlights to shadows; always should be <= 1
      else:
          extremes = shadows / highlights
          
      print(f"High to mid: {highToMid}")
      print(f"Shad to mid: {lowToMid}")
      print(f"High/Shad ratio: {extremes}")
      
      contrastIndex = highToMid * lowToMid * extremes # Unitless index of "how contrasting" the channel is
      
      print(contrastIndex)
      
      return(contrastIndex)


  #Kaleb Lee 1/30/2023 - Test of picking color channel
  redC = contrastValues(redarray)
  greenC = contrastValues(greenarray)
  blueC = contrastValues(bluearray)

  # By default, we will simply use the red channel
  if (blueC > greenC) and (blueC > greenC):
      channelIn = bluearray
  elif (greenC > blueC) and (greenC > redC):
      channelIn = greenarray
  else:
      channelIn = redarray

  #gaussian filter code - Joseph Huang 1/20/23

  gaussianWindow = (np.array([[1,2,1],[2,4,2],[1,2,1]]))/16
  #gaussianWindow = (np.array([[1,4,7,4,1],[4,16,26,16,4],[7,26,41,26,7],[4,16,26,16,4],[1,4,7,4,1]]))/273
  #gaussianWindow = (np.array([[0,0,1,2,1,0,0],[0,3,13,22,13,3,0],[1,13,59,97,59,13,1],[2,22,97,159,97,22,2],[1,13,59,97,59,13,1],[0,3,13,22,13,3,0],[0,0,1,2,1,0,0]]))/1003
  gaussian = signal.convolve2d(channelIn, gaussianWindow)  
  plt.imshow(gaussian, cmap='gray')

  #gradient calc. (Basically Sobel) - Joseph Huang 1/21/23

  #Set dx and dy kernals 
  dx = np.array([[-1,0,1],[-2,0,2],[-1,0,1]]).astype(np.float64) 
  dy = np.array([[-1,-2,-1],[0,0,0],[1,2,1]]).astype(np.float64)
  
  gx = signal.convolve2d(gaussian,dx)  
  gy = signal.convolve2d(gaussian,dy) 
  sobel = np.sqrt(gx**2 + gy**2)
  theta = np.arctan2(gy, gx)

  plt.imshow(sobel,cmap='gray')

  #non-maximum supression - Joseph Huang 1/23/23

  #get shape of the image
  rows, cols = sobel.shape

  #start with array of zeros
  thinned = np.zeros((rows,cols))

  #theta is based on direction of gradient calcultion in sobel 
  direction = theta * 180 / np.pi  #NOTE to self: direction is a numpy ndarray

  #reference "https://www.statology.org/numpy-replace/" for this function
  direction[direction < 0] += 180
  direction[direction > 180] -= 180

  #reference used to get hint on directions approach, noted in confluence
  for i in range(rows - 1):
    for j in range(cols - 1):
    
      #NOTE to self: (0,0) is at top left corner of image. Make sure to check i and j additions for each case
      #direction is E and W
      #direction is between 0 and 22.5 because once it goes above 22.5, it would be facing the NE pixel or SW pixel.
      if (0 <= direction[i,j] <= 22.5):
        temp1 = sobel[i, j + 1]
        temp2 = sobel[i, j - 1]
                  
      #direction is NE and SW
      #direction is between 22.5 and 67.5 because it would be facing the N pixel
      elif (22.5 < direction[i,j] <= 67.5):
        temp1 = sobel[i + 1, j - 1]
        temp2 = sobel[i - 1, j + 1]
                  
      #direction is N and S
      #past 112.5 and it would be NW and SE
      elif (67.5 < direction[i,j] <= 112.5):
        temp1 = sobel[i + 1, j]
        temp2 = sobel[i - 1, j]

      #direction is NW and SE
      #past 157.5 would make direction E and W again
      elif (112.5 < direction[i,j] <= 157.5):
        temp1 = sobel[i - 1, j - 1]
        temp2 = sobel[i + 1, j + 1]

      #E and W again, values are restricted to be between 0 and 180 above
      elif (157.5 < direction[i,j] <= 180):
        temp1 = sobel[i, j + 1]
        temp2 = sobel[i, j - 1]

      #keep most intense pixel
      #If the sobel pixel is more intense the two around it, then keep the pixel
      #else make it 0
      if (sobel[i, j] >= temp1) and (sobel[i, j] >= temp2):
        thinned[i, j] = sobel[i, j]
      else:
        thinned[i, j] = 0

  plt.imshow(thinned,cmap='gray')

  #Double Thresholding - Joseph Huang 1/24/23

  upperThresh = 230
  lowerThresh = 100

  row, col = thinned.shape
  doubleThresh = np.zeros((row,col))

  #find location of pixel that are stronger than the upper threshold 
  strong_x, strong_y = np.where(thinned > upperThresh)

  #find location of pixel that is between lower and uppper threshold
  weak_x, weak_y = np.where((thinned <= upperThresh) & (thinned >= lowerThresh))
      
  #set pixels which were above the upper threshold to 255
  doubleThresh[strong_x, strong_y] = 255

  #set pixels which are between the upper and lower threshold to 25 (indicating weak)
  doubleThresh[weak_x, weak_y] = 25

  plt.imshow(doubleThresh,cmap='gray')

  #hysteresis thesholding - Joseph Huang 1/28/23
  r, c = doubleThresh.shape  
  for i in range(r - 1):
    for j in range(c - 1):
      if (doubleThresh[i , j] == 25):
        if (doubleThresh[i + 1, j - 1] == 255):
          doubleThresh[i, j] = 255
        elif (doubleThresh[i + 1, j] == 255):
          doubleThresh[i, j] = 255
        elif (doubleThresh[i + 1, j + 1] == 255):
          doubleThresh[i, j] = 255
        elif (doubleThresh[i, j - 1] == 255): 
          doubleThresh[i, j] = 255
        elif (doubleThresh[i, j + 1] == 255):
          doubleThresh[i, j] = 255
        elif (doubleThresh[i - 1, j - 1] == 255):
          doubleThresh[i, j] = 255
        elif (doubleThresh[i - 1, j] == 255): 
          doubleThresh[i, j] = 255
        elif (doubleThresh[i - 1, j + 1] == 255):
          doubleThresh[i, j] = 255
        else:
          doubleThresh[i, j] = 0
  return doubleThresh

# plt.imshow(doubleThresh,cmap='gray')
#Folder location for training data (AH) 2/6/2023
folder = []
# local_download_path = "/content/drive/MyDrive/Flower Images/normal_images/Vanilla Ice Sunflower"
# local_download_path = "/content/drive/MyDrive/Flower Images/normal_images/Midnight Marvel Hibiscus"
local_download_path = "/content/drive/MyDrive/Flower Images/normal_images/Diablo Cosmo"

#File names in single list (AH) 2/6/2023 
for filename in os.listdir(local_download_path):
    if filename.endswith("jpg") or filename.endswith("JPG"): 
        # Your code comes here such as 
        print(filename)
        folder.append(filename)

#saves grayscale image (AH) 2/6/2023
from PIL import Image
def save_grey_image(filename: str, image: np.ndarray):
    im = Image.fromarray(image)
    im = im.convert("L")
    im.save(filename)

#Loops through training images to apply canny and save to different folder  (AH) 2/6/2023
local_upload_path = "/content/drive/MyDrive/Flower Images/canny_images/Diablo"
for file in folder:
  filePath = os.path.join(local_download_path, file)
  rawImage = plt.imread(filePath)
  cannyImage = canny(rawImage)
  canny_path = os.path.join(local_upload_path, file)
  save_grey_image(canny_path, cannyImage)
  print(canny_path)

val_ds = tf.keras.utils.image_dataset_from_directory(
  "/content/drive/MyDrive/test_images",
  label_mode='int',
  color_mode="grayscale",
  shuffle="False",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=6)

for images, labels in val_ds.take(1):
  prediction = model.predict(images)
  print(labels)
  print(images[0].shape)
  [print(x) for x in prediction[0]]

fig, ax = plt.subplots(6)
fig.set_size_inches(12,12)
print(labels)
for idx in range(6):
    print(labels[idx])
    [print(x) for x in prediction[idx]]
    image = tf.transpose(images[idx], perm=[2,0,1])
    ax[idx].imshow(image[0], cmap="gray")

